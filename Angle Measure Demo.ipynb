{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import copy\n",
    "import os \n",
    "import gc \n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "from src.utils import *\n",
    "from src.client import *\n",
    "from src.clustering import *\n",
    "from src.data import *\n",
    "from src.models import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "matplotlib.use('nbagg')\n",
    "import pylab\n",
    "from matplotlib.pyplot import subplots\n",
    "import pickle \n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args: \n",
    "    num_users = 100\n",
    "    seed = 1\n",
    "    gpu = 1\n",
    "    \n",
    "    ## CIFAR-10 has 50000 training images (5000 per class), 10 classes, 10000 test images (1000 per class)\n",
    "    ## CIFAR-100 has 50000 training images (500 per class), 100 classes, 10000 test images (100 per class)\n",
    "    ## MNIST has 60000 training images (min: 5421, max: 6742 per class), 10000 test images (min: 892, max: 1135\n",
    "    ## per class) --> in the code we fixed 5000 training image per class, and 900 test image per class to be \n",
    "    ## consistent with CIFAR-10 \n",
    "    \n",
    "    ## CIFAR-10 Non-IID 250 samples per label for 2 class non-iid is the benchmark (500 samples for each client)\n",
    "    \n",
    "    nsample_pc = 250  ## number of samples per class for each client \n",
    "    nclass = 2        ## number of classes or shards for each client\n",
    "    model = 'simple-cnn' ## options: lenet5\n",
    "    dataset = 'fmnist'  ## options: mnist, cifar10, cifar100\n",
    "    datadir = '../data/'\n",
    "    logdir = '../logs/'\n",
    "    partition = 'noniid-#label2'\n",
    "    alg = 'cluster_fl'\n",
    "    savedir = '../save/'\n",
    "    beta = 0.1\n",
    "    local_view = True\n",
    "    batch_size= 10\n",
    "    noise = 0\n",
    "    noise_type = 'level'\n",
    "    \n",
    "    rounds = 200\n",
    "    frac = 0.1\n",
    "    local_bs = 10\n",
    "    local_ep = 10\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    \n",
    "    cluster_alpha = 3.5\n",
    "    nclasses = 10 \n",
    "    nsamples_shared = 2500\n",
    "    n_basis = 3\n",
    "    linkage = 'average'\n",
    "   \n",
    "    print_freq = 50\n",
    "    \n",
    "    load_initial = ''\n",
    "    \n",
    "args = Args()\n",
    "\n",
    "torch.cuda.set_device(args.gpu) ## Setting cuda on GPU \n",
    "#torch.manual_seed(args.seed)\n",
    "#np.random.seed(args.seed)\n",
    "\n",
    "args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = 'cifar10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "K: 10\n",
      "partition: noniid-#label2\n",
      "Data statistics Train:\n",
      " {0: {0: 218, 4: 278}, 1: {1: 264, 5: 264}, 2: {2: 264, 6: 228}, 3: {3: 278, 7: 264}, 4: {4: 278, 9: 209}, 5: {5: 264, 6: 228}, 6: {0: 218, 6: 228}, 7: {1: 264, 7: 264}, 8: {2: 264, 8: 264}, 9: {6: 228, 9: 209}, 10: {0: 218, 3: 278}, 11: {1: 264, 7: 264}, 12: {2: 264, 7: 263}, 13: {3: 278, 9: 209}, 14: {4: 278, 5: 264}, 15: {1: 263, 5: 263}, 16: {2: 263, 6: 228}, 17: {6: 228, 7: 263}, 18: {3: 278, 8: 264}, 19: {1: 263, 9: 209}, 20: {0: 218, 5: 263}, 21: {0: 218, 1: 263}, 22: {2: 263, 4: 278}, 23: {3: 278, 9: 209}, 24: {0: 218, 4: 278}, 25: {5: 263, 6: 227}, 26: {6: 227, 9: 209}, 27: {3: 278, 7: 263}, 28: {2: 263, 8: 264}, 29: {1: 263, 9: 209}, 30: {0: 218, 4: 278}, 31: {1: 263, 5: 263}, 32: {1: 263, 2: 263}, 33: {1: 263, 3: 278}, 34: {0: 218, 4: 278}, 35: {5: 263, 6: 227}, 36: {2: 263, 6: 227}, 37: {1: 263, 7: 263}, 38: {5: 263, 8: 263}, 39: {6: 227, 9: 209}, 40: {0: 218, 4: 278}, 41: {1: 263, 7: 263}, 42: {2: 263, 4: 278}, 43: {3: 278, 5: 263}, 44: {4: 278, 9: 208}, 45: {5: 263, 9: 208}, 46: {0: 217, 6: 227}, 47: {7: 263, 8: 263}, 48: {4: 278, 8: 263}, 49: {4: 278, 9: 208}, 50: {0: 217, 7: 263}, 51: {1: 263, 8: 263}, 52: {2: 263, 8: 263}, 53: {3: 278, 8: 263}, 54: {3: 278, 4: 278}, 55: {5: 263, 7: 263}, 56: {6: 227, 7: 263}, 57: {0: 217, 7: 263}, 58: {0: 217, 8: 263}, 59: {3: 278, 9: 208}, 60: {0: 217, 8: 263}, 61: {1: 263, 6: 227}, 62: {0: 217, 2: 263}, 63: {3: 278, 6: 227}, 64: {4: 278, 7: 263}, 65: {5: 263, 6: 227}, 66: {6: 227, 9: 208}, 67: {1: 263, 7: 263}, 68: {5: 263, 8: 263}, 69: {2: 263, 9: 208}, 70: {0: 217, 8: 263}, 71: {1: 263, 6: 227}, 72: {2: 263, 9: 208}, 73: {0: 217, 3: 278}, 74: {0: 217, 4: 277}, 75: {5: 263, 9: 208}, 76: {1: 263, 6: 227}, 77: {2: 263, 7: 263}, 78: {8: 263, 9: 208}, 79: {7: 263, 9: 208}, 80: {0: 217, 3: 278}, 81: {1: 263, 9: 208}, 82: {2: 263, 9: 208}, 83: {3: 277, 8: 263}, 84: {4: 277, 5: 263}, 85: {0: 217, 5: 263}, 86: {2: 263, 6: 227}, 87: {0: 217, 7: 263}, 88: {3: 277, 8: 263}, 89: {4: 277, 9: 208}, 90: {0: 217, 9: 208}, 91: {1: 263, 9: 208}, 92: {2: 263, 5: 263}, 93: {3: 277, 8: 263}, 94: {4: 277, 8: 263}, 95: {0: 217, 5: 263}, 96: {2: 263, 6: 227}, 97: {6: 227, 7: 263}, 98: {3: 277, 8: 263}, 99: {2: 263, 9: 208}} \n",
      "\n",
      "Data statistics Test:\n",
      " {0: {0: 1000, 4: 1000}, 1: {1: 1000, 5: 1000}, 2: {2: 1000, 6: 1000}, 3: {3: 1000, 7: 1000}, 4: {4: 1000, 9: 1000}, 5: {5: 1000, 6: 1000}, 6: {0: 1000, 6: 1000}, 7: {1: 1000, 7: 1000}, 8: {2: 1000, 8: 1000}, 9: {6: 1000, 9: 1000}, 10: {0: 1000, 3: 1000}, 11: {1: 1000, 7: 1000}, 12: {2: 1000, 7: 1000}, 13: {3: 1000, 9: 1000}, 14: {4: 1000, 5: 1000}, 15: {1: 1000, 5: 1000}, 16: {2: 1000, 6: 1000}, 17: {6: 1000, 7: 1000}, 18: {3: 1000, 8: 1000}, 19: {1: 1000, 9: 1000}, 20: {0: 1000, 5: 1000}, 21: {0: 1000, 1: 1000}, 22: {2: 1000, 4: 1000}, 23: {3: 1000, 9: 1000}, 24: {0: 1000, 4: 1000}, 25: {5: 1000, 6: 1000}, 26: {6: 1000, 9: 1000}, 27: {3: 1000, 7: 1000}, 28: {2: 1000, 8: 1000}, 29: {1: 1000, 9: 1000}, 30: {0: 1000, 4: 1000}, 31: {1: 1000, 5: 1000}, 32: {1: 1000, 2: 1000}, 33: {1: 1000, 3: 1000}, 34: {0: 1000, 4: 1000}, 35: {5: 1000, 6: 1000}, 36: {2: 1000, 6: 1000}, 37: {1: 1000, 7: 1000}, 38: {5: 1000, 8: 1000}, 39: {6: 1000, 9: 1000}, 40: {0: 1000, 4: 1000}, 41: {1: 1000, 7: 1000}, 42: {2: 1000, 4: 1000}, 43: {3: 1000, 5: 1000}, 44: {4: 1000, 9: 1000}, 45: {5: 1000, 9: 1000}, 46: {0: 1000, 6: 1000}, 47: {7: 1000, 8: 1000}, 48: {4: 1000, 8: 1000}, 49: {4: 1000, 9: 1000}, 50: {0: 1000, 7: 1000}, 51: {1: 1000, 8: 1000}, 52: {2: 1000, 8: 1000}, 53: {3: 1000, 8: 1000}, 54: {3: 1000, 4: 1000}, 55: {5: 1000, 7: 1000}, 56: {6: 1000, 7: 1000}, 57: {0: 1000, 7: 1000}, 58: {0: 1000, 8: 1000}, 59: {3: 1000, 9: 1000}, 60: {0: 1000, 8: 1000}, 61: {1: 1000, 6: 1000}, 62: {0: 1000, 2: 1000}, 63: {3: 1000, 6: 1000}, 64: {4: 1000, 7: 1000}, 65: {5: 1000, 6: 1000}, 66: {6: 1000, 9: 1000}, 67: {1: 1000, 7: 1000}, 68: {5: 1000, 8: 1000}, 69: {2: 1000, 9: 1000}, 70: {0: 1000, 8: 1000}, 71: {1: 1000, 6: 1000}, 72: {2: 1000, 9: 1000}, 73: {0: 1000, 3: 1000}, 74: {0: 1000, 4: 1000}, 75: {5: 1000, 9: 1000}, 76: {1: 1000, 6: 1000}, 77: {2: 1000, 7: 1000}, 78: {8: 1000, 9: 1000}, 79: {7: 1000, 9: 1000}, 80: {0: 1000, 3: 1000}, 81: {1: 1000, 9: 1000}, 82: {2: 1000, 9: 1000}, 83: {3: 1000, 8: 1000}, 84: {4: 1000, 5: 1000}, 85: {0: 1000, 5: 1000}, 86: {2: 1000, 6: 1000}, 87: {0: 1000, 7: 1000}, 88: {3: 1000, 8: 1000}, 89: {4: 1000, 9: 1000}, 90: {0: 1000, 9: 1000}, 91: {1: 1000, 9: 1000}, 92: {2: 1000, 5: 1000}, 93: {3: 1000, 8: 1000}, 94: {4: 1000, 8: 1000}, 95: {0: 1000, 5: 1000}, 96: {2: 1000, 6: 1000}, 97: {6: 1000, 7: 1000}, 98: {3: 1000, 8: 1000}, 99: {2: 1000, 9: 1000}} \n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "len train_ds_global: 50000\n",
      "len test_ds_global: 10000\n",
      "cifar10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args.local_view = True\n",
    "X_train, y_train, X_test, y_test, net_dataidx_map, net_dataidx_map_test, \\\n",
    "traindata_cls_counts, testdata_cls_counts = partition_data(args.dataset, \n",
    "args.datadir, args.logdir, args.partition, args.num_users, beta=args.beta, local_view=args.local_view)\n",
    "\n",
    "train_dl_global, test_dl_global, train_ds_global, test_ds_global = get_dataloader(args.dataset,\n",
    "                                                                                   args.datadir,\n",
    "                                                                                   args.batch_size,\n",
    "                                                                                   32)\n",
    "\n",
    "print(\"len train_ds_global:\", len(train_ds_global))\n",
    "print(\"len test_ds_global:\", len(test_ds_global))\n",
    "print(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_train = np.arange(len(train_ds_global))\n",
    "labels_train = np.array(train_ds_global.target)\n",
    "# Sort Labels Train \n",
    "idxs_labels_train = np.vstack((idxs_train, labels_train))\n",
    "idxs_labels_train = idxs_labels_train[:, idxs_labels_train[1, :].argsort()]\n",
    "idxs_train = idxs_labels_train[0, :]\n",
    "labels_train = idxs_labels_train[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tinydata = [np.asarray(img).astype('float32') for img in train_ds_global.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_clustering(A, thresh=1.5, linkage='maximum'):\n",
    "    '''\n",
    "    Hierarchical Clustering Algorithm. It is based on single linkage, finds the minimum element and merges\n",
    "    rows and columns replacing the minimum elements. It is working on adjacency matrix. \n",
    "    \n",
    "    :param: A (adjacency matrix), thresh (stopping threshold)\n",
    "    :type: A (np.array), thresh (int)\n",
    "    \n",
    "    :return: clusters\n",
    "    '''\n",
    "    label_assg = {i: i for i in range(A.shape[0])}\n",
    "    \n",
    "    B = copy.deepcopy(A)\n",
    "    step = 0\n",
    "    while A.shape[0] > 1:\n",
    "        np.fill_diagonal(A,-np.NINF)\n",
    "        #print(f'step {step} \\n {A}')\n",
    "        step+=1\n",
    "        ind=np.unravel_index(np.argmin(A, axis=None), A.shape)\n",
    "        \n",
    "        if A[ind[0],ind[1]]>thresh:\n",
    "            print('Breaking HC')\n",
    "            #print(f'A {B}')\n",
    "            break\n",
    "        else:\n",
    "            np.fill_diagonal(A,0)\n",
    "            if linkage == 'maximum':\n",
    "                Z=np.maximum(A[:,ind[0]], A[:,ind[1]])\n",
    "            elif linkage == 'minimum':\n",
    "                Z=np.minimum(A[:,ind[0]], A[:,ind[1]])\n",
    "            elif linkage == 'average':\n",
    "                Z= (A[:,ind[0]] + A[:,ind[1]])/2\n",
    "            \n",
    "            A[:,ind[0]]=Z\n",
    "            A[:,ind[1]]=Z\n",
    "            A[ind[0],:]=Z\n",
    "            A[ind[1],:]=Z\n",
    "            A = np.delete(A, (ind[1]), axis=0)\n",
    "            A = np.delete(A, (ind[1]), axis=1)\n",
    "            \n",
    "            B = copy.deepcopy(A)\n",
    "            if type(label_assg[ind[0]]) == list: \n",
    "                label_assg[ind[0]].append(label_assg[ind[1]])\n",
    "            else: \n",
    "                label_assg[ind[0]] = [label_assg[ind[0]], label_assg[ind[1]]]\n",
    "\n",
    "            label_assg.pop(ind[1], None)\n",
    "\n",
    "            temp = []\n",
    "            for k,v in label_assg.items():\n",
    "                if k > ind[1]: \n",
    "                    kk = k-1\n",
    "                    vv = v\n",
    "                else: \n",
    "                    kk = k \n",
    "                    vv = v\n",
    "                temp.append((kk,vv))\n",
    "\n",
    "            label_assg = dict(temp)\n",
    "\n",
    "    clusters = []\n",
    "    for k in label_assg.keys():\n",
    "        if type(label_assg[k]) == list:\n",
    "            clusters.append(list(flatten(label_assg[k])))\n",
    "        elif type(label_assg[k]) == int: \n",
    "            clusters.append([label_assg[k]])\n",
    "            \n",
    "    #print(label_assg)\n",
    "            \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eq_Basis(A,B):\n",
    "    AB=np.arccos(A.T@B)\n",
    "    A_E=np.zeros((A.shape[0],A.shape[1]))\n",
    "    B_E=np.zeros((B.shape[0],B.shape[1]))\n",
    "    for i in range(AB.shape[0]):\n",
    "        ind = np.unravel_index(np.argmin(AB, axis=None), AB.shape)\n",
    "        AB[ind[0],:]=AB[:,ind[1]]=0\n",
    "        A_E[:,i]=A[:,ind[0]]\n",
    "        B_E[:,i]=B[:,ind[1]]\n",
    "    return  A_E,B_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "\n",
    "def Gau_Lin_ker(A,B,kernel=None):\n",
    "\n",
    "    Sig=np.zeros((A.shape[1],B.shape[1]))\n",
    "    Ker_G=np.zeros((A.shape[1],B.shape[1]))\n",
    "    Ker_L=np.zeros((A.shape[1],B.shape[1]))\n",
    "\n",
    "    for i in range(A.shape[1]):\n",
    "        for j in range(B.shape[1]):\n",
    "            Sig [i,j]= LA.norm(A[:,i]-B[:,j], 2)**2\n",
    "    sigma=Sig.mean()\n",
    "\n",
    "    for i in range(A.shape[1]):\n",
    "        for j in range(B.shape[1]):\n",
    "            Ker_G[i,j]=np.exp(-LA.norm(A[:,i]-B[:,j], 1)**0.9/(2*sigma))\n",
    "            Ker_L[i,j]=np.dot(A[:,i],B[:,j])\n",
    "   \n",
    "    if kernel == \"Gaussian\":\n",
    "        return Ker_G\n",
    "    elif kernel == \"Linear\":\n",
    "        return Ker_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Per Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0\n",
      "Class 1\n",
      "Class 2\n",
      "Class 3\n",
      "Class 4\n",
      "Class 5\n",
      "Class 6\n",
      "Class 7\n",
      "Class 8\n",
      "Class 9\n"
     ]
    }
   ],
   "source": [
    "data_per_class = {}\n",
    "U_per_class = {}\n",
    "K = 3\n",
    "nclass=10\n",
    "for i in range(nclass):\n",
    "    print(f'Class {i}')\n",
    "    inds = np.where(labels_train==i)[0]\n",
    "    idx = idxs_train[inds].astype(int)\n",
    "    length = len(idx)\n",
    "\n",
    "    #length = 500\n",
    "    data_per_class[i] = np.array(train_ds_global.data[idx]).reshape(length, -1).T.astype(float)\n",
    "    \n",
    "    u1_temp, sh1_temp, vh1_temp = np.linalg.svd(data_per_class[i], full_matrices=False)\n",
    "    u1_temp=u1_temp/np.linalg.norm(u1_temp, ord=2, axis=0)\n",
    "    U_per_class[i] = u1_temp[:, 0:K]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in arccos\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# clients_idxs = np.arange(10)\n",
    "# adj_mat = calculating_adjacency(clients_idxs, U_per_class)\n",
    "# adj_mat = ((180/np.pi)/100)*adj_mat\n",
    "\n",
    "num = nclass\n",
    "\n",
    "sim_angle_min = np.zeros([num, num])\n",
    "sim_angle_tr = np.zeros([num, num])\n",
    "\n",
    "for i in range(num):\n",
    "    for j in range(num):\n",
    "        #kk = selected_clients[i]\n",
    "        #ll = selected_clients[j]\n",
    "        F, G = Eq_Basis (U_per_class[i],U_per_class[j])\n",
    "        #F = copy.deepcopy(U_per_class[i])\n",
    "        #G = copy.deepcopy(U_per_class[j])\n",
    "        F_in_G = np.clip(F.T@G, a_min = -1, a_max = +1)\n",
    "\n",
    "        Angle = np.arccos(np.abs(F_in_G))\n",
    "        sim_angle_min[i,j] =  (180/np.pi)*np.min(Angle) \n",
    "        sim_angle_tr[i,j] =(180/np.pi)*np.trace(Angle)\n",
    "\n",
    "        #sim_mat[i,j] =  100*np.min(Angle) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    6.83  6.55  8.65  9.29 10.48 10.78  7.56  6.66  8.99]\n",
      " [ 6.83  0.    7.86  9.14  9.83 11.18  9.64  8.23  6.89  5.73]\n",
      " [ 6.55  7.86  0.    4.14  3.69  6.36  5.41  3.66 10.46 11.28]\n",
      " [ 8.65  9.14  4.14  0.    3.34  3.79  3.85  4.82 12.44 13.05]\n",
      " [ 9.29  9.83  3.69  3.34  0.    4.5   3.38  4.65 13.03 13.64]\n",
      " [10.48 11.18  6.36  3.79  4.5   0.    5.64  7.43 13.48 15.29]\n",
      " [10.78  9.64  5.41  3.85  3.38  5.64  0.    5.4  13.82 13.33]\n",
      " [ 7.56  8.23  3.66  4.82  4.65  7.43  5.4   0.   11.47 10.67]\n",
      " [ 6.66  6.89 10.46 12.44 13.03 13.48 13.82 11.47  0.    7.44]\n",
      " [ 8.99  5.73 11.28 13.05 13.64 15.29 13.33 10.67  7.44  0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(sim_angle_min.round(decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90.  20.5 19.6 25.9 27.9 31.5 32.3 22.7 20.  27. ]\n",
      " [20.5 90.  23.6 27.4 29.5 33.5 28.9 24.7 20.7 17.2]\n",
      " [19.6 23.6 90.  12.4 11.1 19.1 16.2 11.  31.4 33.8]\n",
      " [25.9 27.4 12.4  0.  10.  11.4 11.5 14.5 37.3 39.1]\n",
      " [27.9 29.5 11.1 10.   0.  13.5 10.1 14.  39.1 40.9]\n",
      " [31.5 33.5 19.1 11.4 13.5  0.  16.9 22.3 40.4 45.9]\n",
      " [32.3 28.9 16.2 11.5 10.1 16.9 90.  16.2 41.5 40. ]\n",
      " [22.7 24.7 11.  14.5 14.  22.3 16.2 90.  34.4 32. ]\n",
      " [20.  20.7 31.4 37.3 39.1 40.4 41.5 34.4  0.  22.3]\n",
      " [27.  17.2 33.8 39.1 40.9 45.9 40.  32.  22.3  0. ]]\n"
     ]
    }
   ],
   "source": [
    "print(sim_angle_tr.round(decimals=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking HC\n",
      "[[0, 8, 1, 9], [2, 7, 3, 4, 6, 5]]\n"
     ]
    }
   ],
   "source": [
    "th = 10\n",
    "clusters = hierarchical_clustering(copy.deepcopy(sim_angle_min), thresh=th, linkage=args.linkage)\n",
    "print(clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
